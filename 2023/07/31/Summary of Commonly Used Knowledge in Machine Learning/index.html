<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Machine Learning Related Knowledge | Kyle's Blog</title><meta name="author" content="Kyle"><meta name="copyright" content="Kyle"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="referrer" content="no-referrer"><meta name="description" content="Summary of Commonly Used Knowledge in Machine Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Machine Learning Related Knowledge">
<meta property="og:url" content="http://example.com/2023/07/31/Summary%20of%20Commonly%20Used%20Knowledge%20in%20Machine%20Learning/index.html">
<meta property="og:site_name" content="Kyle&#39;s Blog">
<meta property="og:description" content="Summary of Commonly Used Knowledge in Machine Learning">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/ML_interview.png">
<meta property="article:published_time" content="2023-07-31T11:03:09.000Z">
<meta property="article:modified_time" content="2023-08-17T07:13:45.563Z">
<meta property="article:author" content="Kyle">
<meta property="article:tag" content="TBC">
<meta property="article:tag" content="ML">
<meta property="article:tag" content="Interview">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/ML_interview.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2023/07/31/Summary%20of%20Commonly%20Used%20Knowledge%20in%20Machine%20Learning/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Machine Learning Related Knowledge',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-08-17 15:13:45'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/transpancy.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://cdn.pixabay.com/photo/2014/04/04/20/12/alphabet-313973_1280.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">5</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">7</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-comments-o"></i><span> 分享</span></a></li><li><a class="site-page child" href="/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/ML_interview.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Kyle's Blog"><span class="site-name">Kyle's Blog</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-comments-o"></i><span> 分享</span></a></li><li><a class="site-page child" href="/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Machine Learning Related Knowledge</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-07-31T11:03:09.000Z" title="发表于 2023-07-31 19:03:09">2023-07-31</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-08-17T07:13:45.563Z" title="更新于 2023-08-17 15:13:45">2023-08-17</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Learning-Notes/">Learning Notes</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Machine Learning Related Knowledge"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="数学基础"><a href="#数学基础" class="headerlink" title="数学基础"></a>数学基础</h1><ol>
<li><h2 id="数据相关："><a href="#数据相关：" class="headerlink" title="数据相关："></a>数据相关：</h2><ol>
<li>基本数据结构：<ul>
<li>标量scalar：单个的数，可作为单个特征的值</li>
<li>向量vector：一组数，有顺序，有方向和大小，可作为特征为单位存储单个对象的信息。</li>
<li>矩阵matrix：相同特征个数的对象集合，可作为多个对象的集合。以向量为单位存储多个对象的信息。</li>
<li>张量tensor：维度更大的矩阵，含有更加丰富的特征信息。以矩阵为单位存储多个更大对象的信息。</li>
</ul>
</li>
<li>数据范数计算：范数用于衡量向量或矩阵的大小<ul>
<li>向量范数：<ul>
<li>1范数：绝对值之和</li>
<li>2范数：平方和开根</li>
<li>负无穷范数：所有绝对值中最小的</li>
<li>正无穷范数：所有绝对值中最大的</li>
<li>p范数：P次幂求和在开P方</li>
</ul>
</li>
<li>矩阵范数：<ul>
<li>1范数列范数：列所有绝对值求和，再去最大值</li>
<li>2范数：矩阵相乘的最大特征值开根</li>
</ul>
</li>
</ul>
</li>
</ol>
</li>
<li><h2 id="函数相关："><a href="#函数相关：" class="headerlink" title="函数相关："></a>函数相关：</h2><ol>
<li>导数：瞬时变化率，是一个极限值</li>
<li>偏导数：多元函数，沿某个走标轴的瞬时变化率，是一个极限值</li>
</ol>
</li>
<li><h2 id="特征相关："><a href="#特征相关：" class="headerlink" title="特征相关："></a>特征相关：</h2><ol>
<li>特征值与特征向量：</li>
<li>奇异值与特征值：</li>
</ol>
</li>
<li><h2 id="概率分布与随机变量："><a href="#概率分布与随机变量：" class="headerlink" title="概率分布与随机变量："></a>概率分布与随机变量：</h2><ol>
<li>为什么使用概率：机器算法的设计通常依赖于对数据的概率假设。</li>
<li>变量和随机变量：具有随机性的变量成为随机变量</li>
<li>概率分布：</li>
<li>概率统计计算：<ul>
<li>期望：平均值</li>
<li>方差：变化幅度</li>
<li>协方差：变量相关强度</li>
<li>相关系数：线性相关程度</li>
</ul>
</li>
</ol>
</li>
</ol>
<h1 id="机器学习基础"><a href="#机器学习基础" class="headerlink" title="机器学习基础"></a>机器学习基础</h1><ol>
<li><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><ol>
<li>计算图导数计算：反向传播，利用练市求导法则和隐式函数求导</li>
<li>局部最优与全局最优：</li>
<li>机器学习分类：<ul>
<li>监督学习：已有标签<ul>
<li>数据集的创建和分类：</li>
<li>数据增强：</li>
<li>特征工程：</li>
<li>构建预测模型和损失：</li>
<li>模型训练：</li>
<li>验证和模型选择：</li>
<li>测试及应用：</li>
</ul>
</li>
<li>非监督学习：无标签</li>
<li>半监督式学习：部分有标签</li>
<li>弱监督学习：标签不清不全不准确</li>
</ul>
</li>
<li>模型分类：<ul>
<li>生成式模型：学习联合概率求条件概率。记住的是不同数据的本身特性，关心数据的生成过程。从统计学角度进行分类</li>
<li>判别式模型：学习决策函数，记住的是不同数据的分类边界，不关心数据的生成过程。</li>
</ul>
</li>
<li>代价函数：<ul>
<li>用于找到最优解的目标函数，通过训练代价函数得到参数</li>
<li>最优解即为代价函数的最小值</li>
<li>代价函数非负：算法收敛时代价函数必取最小值，这是要求目标函数有下界，非负更加方便</li>
<li>常见代价函数：<ul>
<li>二次代价函数：易于理解，可能导致梯度爆炸</li>
<li>交叉熵代价函数：代替二次方代价函数，学习速度更快</li>
<li>对数似然代价函数：</li>
</ul>
</li>
</ul>
</li>
<li>损失函数：<ul>
<li>用来衡量算法的运行情况，是一个非负实值函数，预测单个样本？</li>
<li>零一损失：</li>
<li>绝对值损失</li>
<li>平方损失：</li>
<li>对数损失：</li>
<li>指数损失函数：</li>
</ul>
</li>
<li>梯度下降：<ul>
<li>常用优化方法之一：主要有随机梯度下降和批量梯度下降</li>
<li>缺点：极小点收敛速度慢，可能之字下降，不一定嫩刚找到全局最优解，除非损失函数为凸函数</li>
</ul>
</li>
<li>ROC曲线：<ul>
<li>横坐标：所有错误中天生为错的比例</li>
<li>纵坐标：所有正确中天生为正的比例</li>
<li>使用ROC和AUC评价分类器：测试集中正负样本分布变换时，ROC曲线保持不变</li>
</ul>
</li>
<li>类别不平衡：<ul>
<li>扩大数据集</li>
<li>大类数据欠采样</li>
<li>小类数据过采样</li>
<li>使用新评价指标</li>
<li>数据代价加权</li>
</ul>
</li>
</ol>
</li>
<li><h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h2><ol>
<li>基本原理：是一个分而治之的决策过程，有自上而下的停止阈值法，也有自下而上的剪枝法。</li>
<li>三要素：<ul>
<li>特征选择：</li>
<li>决策树生成：根据特征评估标准自上而下递归生成子节点</li>
<li>剪枝：容易过拟合，需要缩小树规模结构，缓解过拟合，分为预剪枝和后剪枝</li>
</ul>
</li>
<li>优缺点：<ul>
<li>优点：易理解、适用于小数据集、多输出、缺失值不敏感、效率高</li>
<li>缺点：连续字段难预测、容易出现过拟合、类别太多时会出错、特征关联性较强时表现不佳、</li>
</ul>
</li>
</ol>
</li>
<li><h2 id="支持向量机："><a href="#支持向量机：" class="headerlink" title="支持向量机："></a>支持向量机：</h2><ol>
<li>基本概念：<ul>
<li>支持向量：可以进行确定分类的数据成为支持向量</li>
<li>支持向量机：通过支持向量运算的分类器，是一种二分类模型，目的是寻找一个超平面来对样本进行分割分割原则是便捷最大化。最终转化为凸二次规划问题。</li>
</ul>
</li>
<li>模型分类：<ul>
<li>线性可分支持向量机：训练样本线性可分，通过硬边界最大化</li>
<li>线性支持向量机：训练样本近似线性可分，通过软边界最大化</li>
<li>非线性支持向量机：训练样本线性不可分时，通过核技巧和软边界最大化</li>
</ul>
</li>
<li>适用场景：<ul>
<li>线性可分：数据存在于N维空间里，寻找一个N-1维的超平面，将数据分为两部分，超平面很多时，选择到每边数据点距离最大的称为最大边距分类器。</li>
<li>非线性分类：结合拉格朗日乘子法以及KKT条件，和核函数可以生成非线性分类器</li>
</ul>
</li>
<li>核函数：<ul>
<li>原坐标系中线性不可分的数据用核函数投影到另一个空间，尽量使得数据在新的空间里线性可分</li>
<li>避免了维数灾难，无需知道非线性变换函数，可以和不同的算法结合</li>
</ul>
</li>
<li>对偶问题：<ul>
<li>讲原始约束转换为对偶约束更容易求解</li>
<li>可以很自然引用核函数</li>
<li>对偶问题都是凸优化问题</li>
</ul>
</li>
<li>算法优缺点：<ul>
<li>优点：具有坚实理论基础，避免了维数灾难，使得算法简单且鲁棒性强，转化为凸优化问题之后可以获得全局最小值。在小样本训练集上获得良好效果，结构化风险最小，避免了过拟合</li>
<li>缺点：对大样本难以实施，多分类问题难以解决，对缺失数据敏感，对参数和核函数选择敏感</li>
</ul>
</li>
</ol>
</li>
<li><h2 id="贝叶斯分类器："><a href="#贝叶斯分类器：" class="headerlink" title="贝叶斯分类器："></a>贝叶斯分类器：</h2><ul>
<li>极大似然估计原理：利用已知的样本结果，反推最大可能得出结果的参数值</li>
<li>贝叶斯分类器原理：通过相关概率已知的情况下利用误判损失来选择最优的类别分类<ul>
<li>朴素贝叶斯分类器：所有特征相互独立</li>
<li>半朴素贝叶斯分类器：所有特征组内相关，组间独立</li>
</ul>
</li>
</ul>
</li>
<li><h2 id="EM算法："><a href="#EM算法：" class="headerlink" title="EM算法："></a>EM算法：</h2><ul>
<li>最大期望算法，是一类通过迭代进行极大似然估计的优化算法，通过作为牛顿迭代法的替代。</li>
<li>基本步骤：<ul>
<li>计算期望，利用隐藏变量的现有估计值，计算其最大似然估计值。</li>
<li>最大化：最大化最大似然值来计算参数的值。</li>
</ul>
</li>
</ul>
</li>
<li><h2 id="降维和聚类："><a href="#降维和聚类：" class="headerlink" title="降维和聚类："></a>降维和聚类：</h2></li>
</ol>
<h1 id="深度学习基础"><a href="#深度学习基础" class="headerlink" title="深度学习基础"></a>深度学习基础</h1><ol>
<li><h2 id="基本概念-1"><a href="#基本概念-1" class="headerlink" title="基本概念"></a>基本概念</h2><ol>
<li>神经网络的组成<ul>
<li>感知机：多参数线性分段函数</li>
<li>多层感知机：多参数线性分段函数的嵌套函数</li>
</ul>
</li>
<li>常用模型结构：<ul>
<li>RNN、CNN、LSTM、Transformer</li>
</ul>
</li>
<li>为什么需要深层学习：<ul>
<li>特征递进式学习算法，浅层学习低层次的简单特征，深层特征基于学习到的浅层特征继续学习高级特征</li>
<li>深层网络隐藏单元的数量较少，隐藏层数目较多，浅层网络想达到同样的计算结果需要指数级增长的单元数量才能达到。</li>
</ul>
</li>
<li>为什么深层网络难以训练：<ul>
<li>梯度消失：通过隐藏层从后向前看，梯度会越来越小，前面层学习显著慢于后面层的学习，受到学习率、网络参数初始化、激活函数边际效应等影响</li>
<li>梯度爆炸：梯度在网络更新中不断累计，变成更大的梯度，导致网络权重值的大幅更新，使得网络不稳定，极端情况下权重值溢出</li>
<li>权重矩阵 退化导致模型有效自由度减少：参数空间中学习的退化速度减慢，导致减少了模型的有效维数，网络的可用自由度对学习中梯度的范数的贡献不均衡，随着相乘矩阵的数量增加，矩阵的乘机变得越来越退化。</li>
</ul>
</li>
<li>深度学习和机器学习有什么不同：<ul>
<li>机器学习：是通过计算机概率论统计学等知识，输入数据让计算机学的新知识，是训练数据去优化目标函数</li>
<li>深度学习：是一种特殊的机器学习，将世界表示为嵌套的层次结构，每个表示都与更简单的特征相关</li>
<li>传统机器学习需要定义手工特征，依赖于任务的特异性以及设计特征的专家经验，深度学习可以从大数据中先学习简单的特征，并从中逐渐学习更为复杂的抽象特征，不依赖于人工的特征工程。</li>
</ul>
</li>
</ol>
</li>
<li><h2 id="网络操作和计算："><a href="#网络操作和计算：" class="headerlink" title="网络操作和计算："></a>网络操作和计算：</h2><ol>
<li>前向传播和反向传播<ul>
<li>前向传播：加权和，偏置项，激活函数</li>
<li>反向传播：链式求导，梯度下降</li>
</ul>
</li>
<li>计算神经网络的输出：嵌套输出</li>
<li>计算卷积神经网络的输出：遍历查看</li>
<li>计算池化层输出值：区域挑选</li>
</ol>
</li>
<li><h2 id="超参数："><a href="#超参数：" class="headerlink" title="超参数："></a>超参数：</h2><ol>
<li>什么是超参数：<ul>
<li>超参数是在开始学习过程之前设置的参数，而不是通过训练得到的参数数据</li>
<li>通常存在于：定义模型的复杂性和学习能力。不能从模型训练的数据中学习，需要预先定义，可以设置不同的值，比如算法中的学习率，梯度下降迭代的数量，隐藏层的数目，隐藏层的单元数目、激活函数等</li>
</ul>
</li>
<li>如何寻找超参数的最优值：<ul>
<li>总有一些难调的超参数、比如权重衰减大小、高斯核宽度等</li>
<li>可以通过猜测和检查，根据经验和直觉来选择参数</li>
<li>通过网格搜索让计算机尝试在一定范围内均匀分布的一组值</li>
<li>随机搜索：让计算机随机挑选一组值</li>
<li>贝叶斯优化：使用贝叶斯优化超参数，但贝叶斯优化算法本身就需要很多参数</li>
<li>MITIE方法：在好的初始猜测的前提下进行局部优化、</li>
<li>最新的LIPO全局优化方法，不需要参数而且比随机搜索方法更好</li>
</ul>
</li>
<li>超参数搜索一般过程：<ul>
<li>数据集划分：训练集、验证集、测试集</li>
<li>在训练集上进行模型参数优化</li>
<li>在验证集上进行模型超参数搜索</li>
<li>反复重复确定模型的参数和超参数</li>
</ul>
</li>
</ol>
</li>
<li><h2 id="激活函数："><a href="#激活函数：" class="headerlink" title="激活函数："></a>激活函数：</h2><ol>
<li>为什么需要激活函数<ul>
<li>对模型学习有作用？</li>
<li>为输出信号引入非线性因素，可以使得方程复杂度提高，可以实现更加全面的映射</li>
<li>还可以把当前特征空间通过一定线性映射转换到另一空间，使数据更好分类</li>
</ul>
</li>
<li>常见激活函数<ul>
<li>sigmoid：</li>
<li>tanh</li>
<li>relu</li>
<li>leak relu</li>
<li>softplus</li>
</ul>
</li>
<li>常见激活函数的导数</li>
<li>激活函数的性质<ul>
<li>非线性：</li>
<li>可微性：</li>
<li>单调性：</li>
</ul>
</li>
<li>如何选择激活函数<ul>
<li>二分类：输出层选择sigmoid，其它层全部relu</li>
<li>隐藏层不确定，通常relu，优点是负值时，导数等于0</li>
<li>sigmoid：除了输出层是二分类，其它基本不会用它</li>
<li>tanh函数：几乎适用所有场合</li>
<li>如果遇到死的神经元，可以使用leak relu</li>
</ul>
</li>
<li>relu激活函数的优点<ul>
<li>区间变动很大时，relu激活函数的导数或者激活函数斜率都会大于零，学习起来更快</li>
<li>sigmoid和tanh的导数在正负饱和区梯度接近0，造成梯度弥散</li>
<li>relu进入负半区时梯度为0，神经元此时不会训练，造成稀疏性，leak relu不会产生这个问题</li>
</ul>
</li>
<li>什么时候选择线性激活函数<ul>
<li>输出层大多数线性激活函数</li>
<li>一般使用很少</li>
</ul>
</li>
<li>如何理解relu是非线性激活函数<ul>
<li>单侧抑制</li>
<li>相对宽阔的兴奋边界</li>
<li>稀疏激活性</li>
</ul>
</li>
<li>softmax定义<ul>
<li>计算所有可能中某种可能得概率</li>
</ul>
</li>
<li>softmax如何用于多分类<ul>
<li>在多分类时，将多个神经元的输出，映射到【0,1】区间，然后选取概率最大的值</li>
</ul>
</li>
<li>交叉熵代价函数定义<ul>
<li>交叉熵是非负的</li>
<li>训练值接近目标值时，交叉熵接近0</li>
</ul>
</li>
<li>tanh为什么比sigmoid收敛快<ul>
<li>tanh梯度消失问题比sigmoid轻，所以收敛速度快</li>
</ul>
</li>
<li>内聚外斥centerloss</li>
</ol>
</li>
<li><p>batchsize</p>
<ol>
<li>为什么需要batchsize<ul>
<li>数据集较小时，采用全数据集时全数据集的方向更好代表样本总体，但是不同权重的梯度值差别巨大，选取一个全局学习率很苦难。</li>
<li>数据集较大时，单次载入数据变得不可行</li>
</ul>
</li>
<li>如何选择batchsize<ul>
<li>假如每次都训练一个样本，线性神经元在均方误差代价函数的错误面是一个抛物面，横截面是一个椭圆，对多层神经元，非线性网络，在局部依然近似抛物面。每次修正时难以达成一致</li>
<li>批梯度下降法，如果数据集足够充分，那么用一般的训练数据训练出来的梯度与全部数据训练出来的梯度几乎是一样的</li>
</ul>
</li>
<li>合理范围内增大batchsize有何好处<ul>
<li>内存利用率提高了，矩阵乘法并行化效率提高</li>
<li>跑完一个epoch 所需的迭代次数减少，处理数据量的速度进一步加快</li>
<li>在一定范围内，一般来说batchsize越大，确定的下降方向越准</li>
</ul>
</li>
<li>盲目增大batchsize有何坏处<ul>
<li>内存容量容易撑不住</li>
<li>每次迭代时间变长，参数的修正也就显得缓慢</li>
<li>增大到一定程度，下降方向基本不再变化</li>
</ul>
</li>
<li>batchsize调节对训练影响如何<ul>
<li>batchsize太小，模型效果糟糕</li>
<li>增大时处理数据的速度变快</li>
<li>增大时达到相同精度的epoch越来越多</li>
<li>达到某个值时，达到时间上最优</li>
</ul>
</li>
</ol>
</li>
<li><p>归一化</p>
<ol>
<li>什么是归一化<ul>
<li>归纳统一样本的统计分布性，归一化在0-1之间统计的概率分布，在-1-1之间是统计的坐标分布</li>
<li>保证基本度量单位的统一</li>
<li>0-1分布时当所有信号都为正值，隐含层权值只能同时增加或减小，从而导致学习速度变慢</li>
<li>数据中常见的奇异样本数据会增加网络的训练时间，为避免这种情况需要进行输入信号的归一化</li>
</ul>
</li>
<li>为什么归一化<ul>
<li>为了后续数据的统一处理</li>
<li>为了使程序收敛加快</li>
<li>为了避免神经元饱和，避免梯度为零</li>
</ul>
</li>
<li>为什么归一化有用<ul>
<li>未归一化的梯度下降是按照垂直等高线之字寻解 ，迭代次数较多</li>
<li>归一化之后的梯度下降能更快得到收敛</li>
</ul>
</li>
<li>归一化类型有哪些<ul>
<li>线性归一化：适合数值比较集中的情况</li>
<li>标准差标准化：</li>
<li>非线性归一化：适合数据分化较大的场景</li>
</ul>
</li>
<li>局部响应归一化作用<ul>
<li>LRN是一种提高深度学习准确度的技术，一般在激活池化之后，可提高模型的泛化能力</li>
</ul>
</li>
<li>如何理解局部响应归一化<ul>
<li>仿造生物学上活跃神经元对相邻神经元的抑制现象</li>
</ul>
</li>
<li>批归一化<ul>
<li>对神经网络的中间层也进行归一化处理batch normalization</li>
</ul>
</li>
<li>批归一化优点<ul>
<li>减少了人为参数选择，在某些情况下取消dropout和l2正则化参数</li>
<li>减少学习率的要求，现在的我们使用较大或较小的学习率，算法都能快速收敛</li>
<li>不在使用局部归一化</li>
<li>破坏原有的数据分布，可以缓解过拟合</li>
<li>减少梯度消失，加快收敛速度，提高训练精度</li>
</ul>
</li>
<li>批归一化算法流程<ul>
<li>上一层输出结果计算均值</li>
<li>上一层输出数据的标准差</li>
<li>归一化处理</li>
<li>数据重构</li>
</ul>
</li>
<li>批归一化和群组归一化比较<ul>
<li>批归一化可以让网络并行训练，批量变小时误差会迅速增加</li>
<li>群组归一化，在组内计算归一化的均值和方差</li>
</ul>
</li>
<li>weight normalization 和 batch normalization比较<ul>
<li>都属于参数重写方法，只是采用的方式不同，前者只对权重标准化</li>
<li>前者适用于RNN，比后者引入更少的噪声，以及不需要额外的存储空间来保存mini batch的均值和方差，但是需要注意参数初始值的选择</li>
</ul>
</li>
<li>batch normalization在什么时候用比较合适<ul>
<li>每个minibatch较大，数据分布比较接近，在训练之前，做好充分的shuffle,不适用于动态的网络结构和RNN网络</li>
</ul>
</li>
</ol>
</li>
<li><p>预训练和微调</p>
<ol>
<li>为什么无监督训练可以帮助深度学习<ul>
<li>网络越深需要的训练样本就过多，监督训练时需要大量标注样本</li>
<li>多层神经网络参数优化十一二高阶非凸优化问题，经常收到收敛较差的局部解</li>
<li>无监督预训练就是训练网络的第一个隐藏层，再依次训练，最后这些训练得到的参数作为网络参数的初始值</li>
</ul>
</li>
<li>什么是模型微调fine tuning<ul>
<li>别人的参数修改后的网络和自己的数据进行训练，使得参数适应自己的数据，这个过程称为微调</li>
</ul>
</li>
<li>微调时候网络参数是否更新<ul>
<li>相当于继续训练，和直接训练的区别的就是初始化的时候，用的是已有的参数</li>
</ul>
</li>
<li>funetuning模型的三种状态<ul>
<li>只预测不训练，相对快简单</li>
<li>训练，只训练最后分类层，微调的模型最终分类以及符合要求，现在只是在他们的基础上进行类别降维</li>
<li>完全训练</li>
</ul>
</li>
</ol>
</li>
<li><p>权重偏差初始化</p>
<ol>
<li>全部初始化为0</li>
<li>全部初始化为相同值</li>
<li>初始化为小的随机数</li>
<li>用根号N分之一校准方差</li>
<li>稀疏初始化</li>
<li>初始化偏差</li>
</ol>
</li>
<li><p>学习率</p>
<ol>
<li>学习率的作用<ul>
<li>决定梯度下降法中前进的步长</li>
</ul>
</li>
<li>学习率衰减常用参数有哪些</li>
<li>分段常数衰减<ul>
<li>实现定义好训练的次数区间，对应不同的区间设置不同的学习率</li>
</ul>
</li>
<li>指数衰减<ul>
<li>以指数衰减方式进行学习率的更新</li>
</ul>
</li>
<li>自然指数衰减<ul>
<li>也是指数转件但是底数为e</li>
</ul>
</li>
<li>多项式衰减</li>
<li>余弦衰减</li>
</ol>
</li>
<li><p>dropout系列问题</p>
<ol>
<li>为什么要正则化<ul>
<li>避免过拟合</li>
</ul>
</li>
<li>为什么正则化有利于预防过拟合</li>
<li>理解dropout正则化<ul>
<li>随机删除网络的神经单元，压缩权重，完成一些预防过拟合的外层正则化</li>
</ul>
</li>
<li>dropout率的选择<ul>
<li>隐含节点dropout率为0.5时效果最好，此时随机生成的网络结构最多</li>
<li>也可以作为一种添加噪声的方法，直接对input进行操作</li>
</ul>
</li>
<li>dropout率的缺点<ul>
<li>代价函数不在明确定义，每次都会随机移除一些节点，如果再三检查梯度下降的性能，实际上是很难进行复查的。</li>
</ul>
</li>
</ol>
</li>
<li><p>深度学习中的数据增强方法</p>
<ul>
<li>对图像颜色的数据增强</li>
<li>尺度变换</li>
<li>水平垂直翻转</li>
<li>平移变换</li>
<li>高斯噪声、模糊处理</li>
<li>类别不平衡数据的增广</li>
</ul>
</li>
<li><p>如何理解internal covariate shift：内部协变量偏移</p>
<p>模型参数更新会导致上层的输入数据分布发生变化、通过层层叠加，高层的输入分布变化会非常剧烈，这就使得高层需要不断去重新适应底层的参数更新。神经网络中每个神经元输入不是独立同分布</p>
</li>
</ol>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/TBC/">TBC</a><a class="post-meta__tags" href="/tags/ML/">ML</a><a class="post-meta__tags" href="/tags/Interview/">Interview</a></div><div class="post_share"><div class="social-share" data-image="/img/ML_interview.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/08/02/Optimization-algorithms-in-AI/" title="Optimization Algorithms in AI"><img class="cover" src="/img/OpA.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Optimization Algorithms in AI</div></div></a></div><div class="next-post pull-right"><a href="/2023/07/31/Supplement%20to%20Knowledge%20in%20Machine%20Learning#1/" title="Supplement to Machine Learning Knowledge #1"><img class="cover" src="/img/ML_interview.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Supplement to Machine Learning Knowledge #1</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/07/31/Supplement%20to%20Knowledge%20in%20Machine%20Learning#1/" title="Supplement to Machine Learning Knowledge #1"><img class="cover" src="/img/ML_interview.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-07-31</div><div class="title">Supplement to Machine Learning Knowledge #1</div></div></a></div><div><a href="/2023/08/02/Optimization-algorithms-in-AI/" title="Optimization Algorithms in AI"><img class="cover" src="/img/OpA.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-02</div><div class="title">Optimization Algorithms in AI</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://cdn.pixabay.com/photo/2014/04/04/20/12/alphabet-313973_1280.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Kyle</div><div class="author-info__description">日常随笔</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">5</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">7</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80"><span class="toc-number">1.</span> <span class="toc-text">数学基础</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%EF%BC%9A"><span class="toc-number">1.1.</span> <span class="toc-text">数据相关：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E7%9B%B8%E5%85%B3%EF%BC%9A"><span class="toc-number">1.2.</span> <span class="toc-text">函数相关：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E7%9B%B8%E5%85%B3%EF%BC%9A"><span class="toc-number">1.3.</span> <span class="toc-text">特征相关：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83%E4%B8%8E%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%EF%BC%9A"><span class="toc-number">1.4.</span> <span class="toc-text">概率分布与随机变量：</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80"><span class="toc-number">2.</span> <span class="toc-text">机器学习基础</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">2.1.</span> <span class="toc-text">基本概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">2.2.</span> <span class="toc-text">决策树</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%9A"><span class="toc-number">2.3.</span> <span class="toc-text">支持向量机：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8%EF%BC%9A"><span class="toc-number">2.4.</span> <span class="toc-text">贝叶斯分类器：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#EM%E7%AE%97%E6%B3%95%EF%BC%9A"><span class="toc-number">2.5.</span> <span class="toc-text">EM算法：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%99%8D%E7%BB%B4%E5%92%8C%E8%81%9A%E7%B1%BB%EF%BC%9A"><span class="toc-number">2.6.</span> <span class="toc-text">降维和聚类：</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80"><span class="toc-number">3.</span> <span class="toc-text">深度学习基础</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5-1"><span class="toc-number">3.1.</span> <span class="toc-text">基本概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E6%93%8D%E4%BD%9C%E5%92%8C%E8%AE%A1%E7%AE%97%EF%BC%9A"><span class="toc-number">3.2.</span> <span class="toc-text">网络操作和计算：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B6%85%E5%8F%82%E6%95%B0%EF%BC%9A"><span class="toc-number">3.3.</span> <span class="toc-text">超参数：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%EF%BC%9A"><span class="toc-number">3.4.</span> <span class="toc-text">激活函数：</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/08/05/Speculation-on-Future-Business-Product-Directions/" title="Speculation on Future Business Product Directions"><img src="/img/industry.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Speculation on Future Business Product Directions"/></a><div class="content"><a class="title" href="/2023/08/05/Speculation-on-Future-Business-Product-Directions/" title="Speculation on Future Business Product Directions">Speculation on Future Business Product Directions</a><time datetime="2023-08-05T06:13:00.000Z" title="发表于 2023-08-05 14:13:00">2023-08-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/08/03/About-PM/" title="About Product Manager"><img src="/img/pm.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="About Product Manager"/></a><div class="content"><a class="title" href="/2023/08/03/About-PM/" title="About Product Manager">About Product Manager</a><time datetime="2023-08-03T06:05:19.000Z" title="发表于 2023-08-03 14:05:19">2023-08-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/08/02/Optimization-algorithms-in-AI/" title="Optimization Algorithms in AI"><img src="/img/OpA.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Optimization Algorithms in AI"/></a><div class="content"><a class="title" href="/2023/08/02/Optimization-algorithms-in-AI/" title="Optimization Algorithms in AI">Optimization Algorithms in AI</a><time datetime="2023-08-02T07:34:39.000Z" title="发表于 2023-08-02 15:34:39">2023-08-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/07/31/Summary%20of%20Commonly%20Used%20Knowledge%20in%20Machine%20Learning/" title="Machine Learning Related Knowledge"><img src="/img/ML_interview.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Machine Learning Related Knowledge"/></a><div class="content"><a class="title" href="/2023/07/31/Summary%20of%20Commonly%20Used%20Knowledge%20in%20Machine%20Learning/" title="Machine Learning Related Knowledge">Machine Learning Related Knowledge</a><time datetime="2023-07-31T11:03:09.000Z" title="发表于 2023-07-31 19:03:09">2023-07-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/07/31/Supplement%20to%20Knowledge%20in%20Machine%20Learning#1/" title="Supplement to Machine Learning Knowledge #1"><img src="/img/ML_interview.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Supplement to Machine Learning Knowledge #1"/></a><div class="content"><a class="title" href="/2023/07/31/Supplement%20to%20Knowledge%20in%20Machine%20Learning#1/" title="Supplement to Machine Learning Knowledge #1">Supplement to Machine Learning Knowledge #1</a><time datetime="2023-07-31T11:03:09.000Z" title="发表于 2023-07-31 19:03:09">2023-07-31</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent"><div id="footer-wrap"><div class="copyright">&copy;2023 By Kyle</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>